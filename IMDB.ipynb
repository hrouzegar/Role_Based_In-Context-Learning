{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vtYnMkwNFMB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ki4ATFHOY3a",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"max_colwidth\", 100)\n",
        "pd.set_option(\"display.max_rows\",10)\n",
        "pd.set_option(\"display.max_columns\",5)\n",
        "DS= pd.read_pickle('balanced_IMDB.pkl');\n",
        "sentiment_data = DS\n",
        "sentiment_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7tKhS7B7PStr"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key='your api key',\n",
        ")"
      ],
      "metadata": {
        "id": "t3qVp84Cbmsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(messages, model=\"gpt-4o\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Yf35JJhnbNRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(messages, model=\"gpt-3.5-turbo-0125\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "t6vp9qTZbOrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Glnv5CoIQlOk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "\n",
        "def connect_with_api(messages):\n",
        "    max_retries = 3\n",
        "    retries = 0\n",
        "\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = get_completion(messages)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            retries += 1\n",
        "            print(f\"Retrying... (Attempt {retries} of {max_retries})\")\n",
        "            time.sleep(1)  # Wait for 1 second before retrying\n",
        "\n",
        "    print(\"Failed to connect with the API after multiple attempts.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o_6ngaONlWk"
      },
      "outputs": [],
      "source": [
        "test_samples_per_sentiment = 996\n",
        "train_samples_per_sentiment = 4\n",
        "test_df = pd.DataFrame()\n",
        "train_df = pd.DataFrame()\n",
        "for sentiment in sentiment_data['sentiment'].unique():\n",
        "    sentiment_df = sentiment_data[sentiment_data['sentiment'] == sentiment]\n",
        "    test_samples = sentiment_df.sample(test_samples_per_sentiment, random_state=1)\n",
        "    train_samples = sentiment_df.drop(test_samples.index).sample(train_samples_per_sentiment, random_state=1)\n",
        "\n",
        "    test_df = pd.concat([test_df, test_samples])\n",
        "    train_df = pd.concat([train_df, train_samples])\n",
        "\n",
        "# Reset the index of the resulting DataFrames\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "train_df = train_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RceCnC4XND-I"
      },
      "outputs": [],
      "source": [
        "def clean_response(response):\n",
        "    response = response.strip().lower()\n",
        "    if 'positive' in response:\n",
        "        return 'positive'\n",
        "    elif 'negative' in response:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Experiment configurations\n",
        "def run_experiment(prompt_design, test_df, train_df, experiment_name):\n",
        "    test_results = []\n",
        "    for index, row in test_df.iterrows():\n",
        "        if prompt_design == \"zeroU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Determine the sentiment of the movie based on the provided review:\n",
        "             For the review provided, classify its sentiment as a single word (without other marks or words like 'sentiment:'), either \"positive\", or \"negative\".\n",
        "```{row['review']}```\"\"\" }]\n",
        "        elif prompt_design == \"zeroSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Determine the sentiment of the movie based on the provided review.\n",
        "             For the review provided, classify its sentiment as a single word (without other marks or words like 'sentiment:'), either \"positive\", or \"negative\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['review']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Determine the sentiment of the movie based on the provided review:\n",
        "             For the review provided, classify its sentiment as a single word (without other marks or words like 'sentiment:'), either \"positive\", or \"negative\".\n",
        "Examples:\n",
        "```{train_df.iloc[0]['review']}``` - {train_df.iloc[0]['sentiment']}\n",
        "```{train_df.iloc[2]['review']}``` - {train_df.iloc[2]['sentiment']}\n",
        "```{train_df.iloc[1]['review']}``` - {train_df.iloc[1]['sentiment']}\n",
        "...\n",
        "```{row['review']}```\"\"\" }]\n",
        "        elif prompt_design == \"fewSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Determine the sentiment of the movie based on the provided review.\n",
        "             For the review provided, classify its sentiment as a single word (without other marks or words like 'sentiment:'), either either \"positive\", or \"negative\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"Examples:\n",
        "```{train_df.iloc[0]['review']}``` - {train_df.iloc[0]['sentiment']}\n",
        "```{train_df.iloc[2]['review']}``` - {train_df.iloc[2]['sentiment']}\n",
        "```{train_df.iloc[1]['review']}``` - {train_df.iloc[1]['sentiment']}\n",
        "...\n",
        "```{row['review']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewSUA\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Determine the sentiment of the movie based on the provided review.\n",
        "            For the review provided, classify its sentiment as a single word (without other marks or words like 'sentiment:'), either \"positive\", or \"negative\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[0]['review']}, {\"role\": \"assistant\", \"content\": train_df.iloc[0]['sentiment']},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[2]['review']}, {\"role\": \"assistant\", \"content\": train_df.iloc[2]['sentiment']},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[1]['review']}, {\"role\": \"assistant\", \"content\": train_df.iloc[1]['sentiment']},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['review']}```\"\"\"}]\n",
        "\n",
        "        prediction = connect_with_api(messages)\n",
        "        print(index, ' ', prediction)\n",
        "\n",
        "        test_results.append({'Index': index, 'review': row['review'], 'Predicted_sentiment': prediction, 'Actual_sentiment': row['sentiment']})\n",
        "\n",
        "    results_df = pd.DataFrame(test_results)\n",
        "    # Calculate structural accuracy before cleaning\n",
        "    valid_sentiment =['positive', 'negative']\n",
        "    results_df['Is_Structurally_Valid'] = results_df['Predicted_sentiment'].apply(lambda x: x.strip().lower() in valid_sentiment)\n",
        "    structural_accuracy = results_df['Is_Structurally_Valid'].mean()\n",
        "\n",
        "    # Calculate F1 Score\n",
        "    results_df['Predicted_sentiment'] = results_df['Predicted_sentiment'].apply(clean_response)\n",
        "    results_df = results_df.dropna(subset=['Predicted_sentiment', 'Actual_sentiment'])\n",
        "    f1 = f1_score(results_df['Actual_sentiment'], results_df['Predicted_sentiment'], average='micro')\n",
        "\n",
        "    print(f\"Experiment: {experiment_name}\")\n",
        "    print(f\"The F1 Score for the predicted sentiment is: {f1}\")\n",
        "    print(f\"The Structural Accuracy is: {structural_accuracy}\")\n",
        "\n",
        "    results_df.to_csv(f\"/content/drive/MyDrive/Colab Notebooks/In_context_learning/{experiment_name}_results.csv\", index=False)\n",
        "    print(f\"Results for {experiment_name} saved to {experiment_name}_results.csv\")"
      ],
      "metadata": {
        "id": "Hys_Gjt3QIsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the experiments\n",
        "run_experiment(\"zeroU\", test_df, train_df, \"Zero-shot User Prompt\")\n"
      ],
      "metadata": {
        "id": "SAVvEZlziUT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(\"zeroSU\", test_df, train_df, \"Zero-shot System and User Prompt\")\n"
      ],
      "metadata": {
        "id": "ynrCPV3lZMLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(\"fewU\", test_df, train_df, \"Few-shot User Prompt\")\n"
      ],
      "metadata": {
        "id": "HuTC5WcJZM3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(\"fewSU\", test_df, train_df, \"Few-shot System and User Prompt\")\n"
      ],
      "metadata": {
        "id": "1HGruLaPZO7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(\"fewSUA\", test_df, train_df, \"Few-shot System, User, and Assistant Prompt\")"
      ],
      "metadata": {
        "id": "FFEU44FwZQjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4dqSKOnNW_e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}