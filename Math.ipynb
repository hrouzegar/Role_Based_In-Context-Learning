{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vtYnMkwNFMB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ki4ATFHOY3a",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"max_colwidth\", 100)\n",
        "pd.set_option(\"display.max_rows\",10)\n",
        "pd.set_option(\"display.max_columns\",5)\n",
        "DS= pd.read_pickle('Balanced_Math.pkl');\n",
        "answer_data = DS\n",
        "answer_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7tKhS7B7PStr"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key='your api key',\n",
        ")"
      ],
      "metadata": {
        "id": "t3qVp84Cbmsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(messages, model=\"gpt-4o\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Yf35JJhnbNRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(messages, model=\"gpt-3.5-turbo-0125\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "t6vp9qTZbOrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Glnv5CoIQlOk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "\n",
        "def connect_with_api(messages):\n",
        "    max_retries = 3\n",
        "    retries = 0\n",
        "\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = get_completion(messages)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            retries += 1\n",
        "            print(f\"Retrying... (Attempt {retries} of {max_retries})\")\n",
        "            time.sleep(1)  # Wait for 1 second before retrying\n",
        "\n",
        "    print(\"Failed to connect with the API after multiple attempts.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o_6ngaONlWk"
      },
      "outputs": [],
      "source": [
        "# test_samples_per_answer = 199\n",
        "# train_samples_per_answer = 1\n",
        "test_samples_per_answer = 49\n",
        "train_samples_per_answer = 1\n",
        "test_df = pd.DataFrame()\n",
        "train_df = pd.DataFrame()\n",
        "for answer in answer_data['answer'].unique():\n",
        "    answer_df = answer_data[answer_data['answer'] == answer]\n",
        "    test_samples = answer_df.sample(test_samples_per_answer, random_state=1)\n",
        "    train_samples = answer_df.drop(test_samples.index).sample(train_samples_per_answer, random_state=1)\n",
        "\n",
        "    test_df = pd.concat([test_df, test_samples])\n",
        "    train_df = pd.concat([train_df, train_samples])\n",
        "\n",
        "# Reset the index of the resulting DataFrames\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "train_df = train_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RceCnC4XND-I"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_response(response):\n",
        "    # Strip leading and trailing whitespace\n",
        "    response = response.strip()\n",
        "\n",
        "    # Define a pattern to capture the answer choice\n",
        "    match = re.search(r'\\b([abcde])\\b', response)\n",
        "\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Experiment configurations\n",
        "def run_experiment(prompt_design, test_df, train_df, experiment_name):\n",
        "    test_results = []\n",
        "    for index, row in test_df.iterrows():\n",
        "        if prompt_design == \"zeroU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Determine the answer of the example based on the provided question:\n",
        "             For the question provided, classify its answer as a single small letter (without other marks or words like 'answer:'), either \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"zeroSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Determine the answer of the example based on the provided question.\n",
        "             For the question provided, classify its answer as a single small letter (without other marks or words like 'answer:'), either \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Determine the answer of the example based on the provided question:\n",
        "             For the question provided, classify its answer as a single small letter (without other marks or words like 'answer:'), either \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']}\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']}\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']}\n",
        "...\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"fewSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Determine the answer of the example based on the provided question.\n",
        "             For the question provided, classify its answer as a single small letter (without other marks or words like 'answer:'), either \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']}\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']}\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']}\n",
        "...\n",
        "```{row['question']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewSUA\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Determine the answer of the example based on the provided question.\n",
        "            For the question provided, classify its answer as a single small letter (without other marks or words like 'answer:'), either \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[0]['question']}, {\"role\": \"assistant\", \"content\": train_df.iloc[0]['answer']},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[2]['question']}, {\"role\": \"assistant\", \"content\": train_df.iloc[2]['answer']},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[3]['question']}, {\"role\": \"assistant\", \"content\": train_df.iloc[3]['answer']},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "\n",
        "        prediction = connect_with_api(messages)\n",
        "        print(index, ' ', prediction)\n",
        "\n",
        "        test_results.append({'Index': index, 'question': row['question'], 'Predicted_answer': prediction, 'Actual_answer': row['answer']})\n",
        "\n",
        "    results_df = pd.DataFrame(test_results)\n",
        "    # Calculate structural accuracy before cleaning\n",
        "    valid_answer = ['A', 'B', 'C', 'D','E']\n",
        "    results_df['Is_Structurally_Valid'] = results_df['Predicted_answer'].apply(lambda x: x.strip().upper() in valid_answer)\n",
        "    structural_accuracy = results_df['Is_Structurally_Valid'].mean()\n",
        "\n",
        "    # Calculate F1 Score\n",
        "    results_df['Predicted_answer'] = results_df['Predicted_answer'].apply(clean_response)\n",
        "    results_df = results_df.dropna(subset=['Predicted_answer', 'Actual_answer'])\n",
        "    f1 = f1_score(results_df['Actual_answer'], results_df['Predicted_answer'], average='micro')\n",
        "\n",
        "    print(f\"Experiment: {experiment_name}\")\n",
        "    print(f\"The F1 Score for the predicted answer is: {f1}\")\n",
        "    print(f\"The Structural Accuracy is: {structural_accuracy}\")\n",
        "\n",
        "    results_df.to_csv(f\"{experiment_name}_results.csv\", index=False)\n",
        "    print(f\"Results for {experiment_name} saved to {experiment_name}_results.csv\")"
      ],
      "metadata": {
        "id": "Hys_Gjt3QIsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qnA12uxJZTyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the experiments\n",
        "run_experiment(\"zeroU\", test_df, train_df, \"Zero-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"zeroSU\", test_df, train_df, \"Zero-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewU\", test_df, train_df, \"Few-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSU\", test_df, train_df, \"Few-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSUA\", test_df, train_df, \"Few-shot System, User, and Assistant Prompt\")"
      ],
      "metadata": {
        "id": "arPcMkwhZVhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Experiment configurations\n",
        "def run_experiment(prompt_design, test_df, train_df, experiment_name):\n",
        "    test_results = []\n",
        "    for index, row in test_df.iterrows():\n",
        "        if prompt_design == \"zeroU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single samall letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"zeroSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single small letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single samall letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']}\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']}\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']}\n",
        "...\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"fewSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single small letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']}\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']}\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']}\n",
        "...\n",
        "```{row['question']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewSUA\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single small letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[0]['question']}, {\"role\": \"assistant\", \"content\": train_df.iloc[0]['answer']},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[2]['question']}, {\"role\": \"assistant\", \"content\": train_df.iloc[2]['answer']},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[3]['question']}, {\"role\": \"assistant\", \"content\": train_df.iloc[3]['answer']},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "\n",
        "        prediction = connect_with_api(messages)\n",
        "        print(index, ' ', prediction)\n",
        "\n",
        "        test_results.append({'Index': index, 'question': row['question'], 'Predicted_answer': prediction, 'Actual_answer': row['answer']})\n",
        "\n",
        "    results_df = pd.DataFrame(test_results)\n",
        "    # Calculate structural accuracy before cleaning\n",
        "    valid_answer = ['A', 'B', 'C', 'D','E']\n",
        "    results_df['Is_Structurally_Valid'] = results_df['Predicted_answer'].apply(lambda x: x.strip().upper() in valid_answer)\n",
        "    structural_accuracy = results_df['Is_Structurally_Valid'].mean()\n",
        "\n",
        "    # Calculate F1 Score\n",
        "    results_df['Predicted_answer'] = results_df['Predicted_answer'].apply(clean_response)\n",
        "    results_df = results_df.dropna(subset=['Predicted_answer', 'Actual_answer'])\n",
        "    f1 = f1_score(results_df['Actual_answer'], results_df['Predicted_answer'], average='micro')\n",
        "\n",
        "    print(f\"Experiment: {experiment_name}\")\n",
        "    print(f\"The F1 Score for the predicted answer is: {f1}\")\n",
        "    print(f\"The Structural Accuracy is: {structural_accuracy}\")\n",
        "\n",
        "    results_df.to_csv(f\"{experiment_name}_results.csv\", index=False)\n",
        "    print(f\"Results for {experiment_name} saved to {experiment_name}_results.csv\")"
      ],
      "metadata": {
        "id": "3wcXWR0u7fAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the experiments\n",
        "run_experiment(\"zeroU\", test_df, train_df, \"Zero-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"zeroSU\", test_df, train_df, \"Zero-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewU\", test_df, train_df, \"Few-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSU\", test_df, train_df, \"Few-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSUA\", test_df, train_df, \"Few-shot System, User, and Assistant Prompt\")"
      ],
      "metadata": {
        "id": "nkqmoD37lbVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Experiment configurations\n",
        "def run_experiment(prompt_design, test_df, train_df, experiment_name):\n",
        "    test_results = []\n",
        "    for index, row in test_df.iterrows():\n",
        "        if prompt_design == \"zeroU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single samall letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "                 After providing the letter answer, explain your rationale and how you arrived at the solution.\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"zeroSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single small letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "                 After providing the letter answer, explain your rationale and how you arrived at the solution.\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single samall letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "                 After providing the letter answer, explain your rationale and how you arrived at the solution.\n",
        "Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']} Explanation : the percent of alcohol in the solution is ( 0.05 ( 40 ) + 2.5 ) / 50 = 4.5 / 50 = 9 % the answer is a\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']} Explanation : total = 100 t = 80 nt = 20 80 * ( 20 / 100 ) = 24 80 * ( 20 / 100 ) = 24 16 + 16 = 32 = > 100 - 32 = 68 % answer : b\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']} Explanation : let the price be = rs . 100 , and number of units sold = 100 then , sale value = rs . ( 100 \\u00d7 100 ) = rs . 10000 new sale value = rs . ( 170 \\u00d7 80 ) = rs . 13600 increase % = 3600 / 10000 \\u00d7 100 = 36 % answer : c\n",
        "...\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"fewSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single small letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "                 After providing the letter answer, explain your rationale and how you arrived at the solution.\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']} Explanation : the percent of alcohol in the solution is ( 0.05 ( 40 ) + 2.5 ) / 50 = 4.5 / 50 = 9 % the answer is a\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']} Explanation : total = 100 t = 80 nt = 20 80 * ( 20 / 100 ) = 24 80 * ( 20 / 100 ) = 24 16 + 16 = 32 = > 100 - 32 = 68 % answer : b\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']} Explanation : let the price be = rs . 100 , and number of units sold = 100 then , sale value = rs . ( 100 \\u00d7 100 ) = rs . 10000 new sale value = rs . ( 170 \\u00d7 80 ) = rs . 13600 increase % = 3600 / 10000 \\u00d7 100 = 36 % answer : c\n",
        "...\n",
        "```{row['question']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewSUA\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "                 Provide the answer as a single small letter (without any additional marks or words like 'answer:'), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "                 After providing the letter answer, explain your rationale and how you arrived at the solution.\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[0]['question']}, {\"role\": \"assistant\", \"content\": f\"\"\" {train_df.iloc[0]['answer']} Explanation : the percent of alcohol in the solution is ( 0.05 ( 40 ) + 2.5 ) / 50 = 4.5 / 50 = 9 % the answer is a\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[2]['question']}, {\"role\": \"assistant\", \"content\": f\"\"\" {train_df.iloc[2]['answer']} Explanation : total = 100 t = 80 nt = 20 80 * ( 20 / 100 ) = 24 80 * ( 20 / 100 ) = 24 16 + 16 = 32 = > 100 - 32 = 68 % answer : b\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": train_df.iloc[3]['question']}, {\"role\": \"assistant\", \"content\": f\"\"\" {train_df.iloc[3]['answer']} Explanation : let the price be = rs . 100 , and number of units sold = 100 then , sale value = rs . ( 100 \\u00d7 100 ) = rs . 10000 new sale value = rs . ( 170 \\u00d7 80 ) = rs . 13600 increase % = 3600 / 10000 \\u00d7 100 = 36 % answer : c\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "\n",
        "\n",
        "        prediction = connect_with_api(messages)\n",
        "        print(index, ' ', prediction)\n",
        "\n",
        "        test_results.append({'Index': index, 'question': row['question'], 'Predicted_answer': prediction, 'Actual_answer': row['answer']})\n",
        "\n",
        "    results_df = pd.DataFrame(test_results)\n",
        "    # Calculate structural accuracy before cleaning\n",
        "    def check_structural_validity(response):\n",
        "        # Check if the response starts with a single lowercase letter among a, b, c, d, e\n",
        "        pattern = r'^[abcde](?!\\w)'\n",
        "        match = re.match(pattern, response.strip().lower())\n",
        "        return bool(match)\n",
        "\n",
        "    valid_answer = ['a', 'b', 'c', 'd', 'e']\n",
        "    results_df['Is_Structurally_Valid'] = results_df['Predicted_answer'].apply(check_structural_validity)\n",
        "    structural_accuracy = results_df['Is_Structurally_Valid'].mean()\n",
        "    # Calculate F1 Score\n",
        "    results_df['Predicted_answer'] = results_df['Predicted_answer'].apply(clean_response)\n",
        "    results_df = results_df.dropna(subset=['Predicted_answer', 'Actual_answer'])\n",
        "    f1 = f1_score(results_df['Actual_answer'], results_df['Predicted_answer'], average='micro')\n",
        "\n",
        "    print(f\"Experiment: {experiment_name}\")\n",
        "    print(f\"The F1 Score for the predicted answer is: {f1}\")\n",
        "    print(f\"The Structural Accuracy is: {structural_accuracy}\")\n",
        "\n",
        "    results_df.to_csv(f\"{experiment_name}_results.csv\", index=False)\n",
        "    print(f\"Results for {experiment_name} saved to {experiment_name}_results.csv\")"
      ],
      "metadata": {
        "id": "SZ0hvZavlcnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the experiments\n",
        "run_experiment(\"zeroU\", test_df, train_df, \"Zero-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"zeroSU\", test_df, train_df, \"Zero-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewU\", test_df, train_df, \"Few-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSU\", test_df, train_df, \"Few-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSUA\", test_df, train_df, \"Few-shot System, User, and Assistant Prompt\")"
      ],
      "metadata": {
        "id": "UEeensOhlbn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Experiment configurations\n",
        "def run_experiment(prompt_design, test_df, train_df, experiment_name):\n",
        "    test_results = []\n",
        "    for index, row in test_df.iterrows():\n",
        "        if prompt_design == \"zeroU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "               Explain your rationale and how you arrived at the solution.\n",
        "               After explaining how reached the answer, Provide the answer as a single small letter (without any additional marks), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"zeroSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "               Explain your rationale and how you arrived at the solution.\n",
        "               After explaining how reached the answer, Provide the answer as a single small letter (without any additional marks), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "        elif prompt_design == \"fewU\":\n",
        "            messages = [{\"role\": \"user\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "               Explain your rationale and how you arrived at the solution.\n",
        "               After explaining how reached the answer, Provide the answer as a single small letter (without any additional marks), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\n",
        "Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']} Explanation : the percent of alcohol in the solution is ( 0.05 ( 40 ) + 2.5 ) / 50 = 4.5 / 50 = 9 % the answer is a\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']} Explanation : total = 100 t = 80 nt = 20 80 * ( 20 / 100 ) = 24 80 * ( 20 / 100 ) = 24 16 + 16 = 32 = > 100 - 32 = 68 % answer : b\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']} Explanation : let the price be = rs . 100 , and number of units sold = 100 then , sale value = rs . ( 100 \\u00d7 100 ) = rs . 10000 new sale value = rs . ( 170 \\u00d7 80 ) = rs . 13600 increase % = 3600 / 10000 \\u00d7 100 = 36 % answer : c\n",
        "...\n",
        "```{row['question']}```\"\"\" }]\n",
        "        elif prompt_design == \"fewSU\":\n",
        "            messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "               Explain your rationale and how you arrived at the solution.\n",
        "               After explaining how reached the answer, Provide the answer as a single small letter (without any additional marks), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\".\"\"\"},\n",
        "                        {\"role\": \"user\", \"content\": f\"\"\"Examples:\n",
        "```{train_df.iloc[0]['question']}``` - {train_df.iloc[0]['answer']} Explanation : the percent of alcohol in the solution is ( 0.05 ( 40 ) + 2.5 ) / 50 = 4.5 / 50 = 9 % the answer is a\n",
        "```{train_df.iloc[2]['question']}``` - {train_df.iloc[2]['answer']} Explanation : total = 100 t = 80 nt = 20 80 * ( 20 / 100 ) = 24 80 * ( 20 / 100 ) = 24 16 + 16 = 32 = > 100 - 32 = 68 % answer : b\n",
        "```{train_df.iloc[3]['question']}``` - {train_df.iloc[3]['answer']} Explanation : let the price be = rs . 100 , and number of units sold = 100 then , sale value = rs . ( 100 \\u00d7 100 ) = rs . 10000 new sale value = rs . ( 170 \\u00d7 80 ) = rs . 13600 increase % = 3600 / 10000 \\u00d7 100 = 36 % answer : c\n",
        "...\n",
        "```{row['question']}```\"\"\"}]\n",
        "\n",
        "        elif prompt_design == \"fewSUA\":\n",
        "           messages = [{\"role\": \"system\", \"content\": f\"\"\"Solve the following math question and determine the correct answer.\n",
        "               Explain your rationale and how you arrived at the solution.\n",
        "               After explaining how reached the answer, Provide the answer as a single small letter (without any additional marks), choosing from: \"a\", \"b\", \"c\", \"d\", or \"e\". \"\"\"},\n",
        "                {\"role\": \"user\", \"content\": train_df.iloc[0]['question']}, {\"role\": \"assistant\", \"content\": f\"\"\" Explanation : the percent of alcohol in the solution is ( 0.05 ( 40 ) + 2.5 ) / 50 = 4.5 / 50 = 9 % the answer is a\"\"\"},\n",
        "                {\"role\": \"user\", \"content\": train_df.iloc[2]['question']}, {\"role\": \"assistant\", \"content\": f\"\"\" Explanation : total = 100 t = 80 nt = 20 80 * ( 20 / 100 ) = 24 80 * ( 20 / 100 ) = 24 16 + 16 = 32 = > 100 - 32 = 68 % answer : b\"\"\"},\n",
        "                {\"role\": \"user\", \"content\": train_df.iloc[3]['question']}, {\"role\": \"assistant\", \"content\": f\"\"\" Explanation : let the price be = rs . 100 , and number of units sold = 100 then , sale value = rs . ( 100 \\u00d7 100 ) = rs . 10000 new sale value = rs . ( 170 \\u00d7 80 ) = rs . 13600 increase % = 3600 / 10000 \\u00d7 100 = 36 % answer : c\"\"\"},\n",
        "                {\"role\": \"user\", \"content\": f\"\"\"```{row['question']}```\"\"\"}]\n",
        "\n",
        "        prediction = connect_with_api(messages)\n",
        "        print(index, ' ', prediction)\n",
        "\n",
        "        test_results.append({'Index': index, 'question': row['question'], 'Predicted_answer': prediction, 'Actual_answer': row['answer']})\n",
        "\n",
        "    results_df = pd.DataFrame(test_results)\n",
        "    # Calculate structural accuracy before cleaning\n",
        "    def check_structural_validity(response):\n",
        "        # Check if the response starts with a single lowercase letter among a, b, c, d, e\n",
        "        pattern = r'^[abcde](?!\\w)'\n",
        "        match = re.match(pattern, response.strip().lower())\n",
        "        return bool(match)\n",
        "\n",
        "    valid_answer = ['a', 'b', 'c', 'd', 'e']\n",
        "    results_df['Is_Structurally_Valid'] = results_df['Predicted_answer'].apply(check_structural_validity)\n",
        "    structural_accuracy = results_df['Is_Structurally_Valid'].mean()\n",
        "    # Calculate F1 Score\n",
        "    results_df['Predicted_answer'] = results_df['Predicted_answer'].apply(clean_response)\n",
        "    results_df = results_df.dropna(subset=['Predicted_answer', 'Actual_answer'])\n",
        "    f1 = f1_score(results_df['Actual_answer'], results_df['Predicted_answer'], average='micro')\n",
        "\n",
        "    print(f\"Experiment: {experiment_name}\")\n",
        "    print(f\"The F1 Score for the predicted answer is: {f1}\")\n",
        "    print(f\"The Structural Accuracy is: {structural_accuracy}\")\n",
        "\n",
        "    results_df.to_csv(f\"{experiment_name}_results.csv\", index=False)\n",
        "    print(f\"Results for {experiment_name} saved to {experiment_name}_results.csv\")"
      ],
      "metadata": {
        "id": "uM_GJTKvlc4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the experiments\n",
        "run_experiment(\"zeroU\", test_df, train_df, \"Zero-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"zeroSU\", test_df, train_df, \"Zero-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewU\", test_df, train_df, \"Few-shot User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSU\", test_df, train_df, \"Few-shot System and User Prompt\")\n",
        "\n",
        "run_experiment(\"fewSUA\", test_df, train_df, \"Few-shot System, User, and Assistant Prompt\")"
      ],
      "metadata": {
        "id": "26_paa0jlb3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}